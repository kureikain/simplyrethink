-# 6. Data Modeling With JOIN

Join is a joy to work with in my opinion. It makes data model easier to design. 
Without joy, we have to either embed or joinging
data with our code instead of database taking care of that for us. With embedding
document, we will hit a limit point about document size because the document 
will usually loaded into the memory. Embedding document has its own advantages
such as: query data is simple, but this section will focus on data modeling with
*JOIN*.

# Using Join

## eqJoin

In RethinkDB, **JOIN** is automatically distributed, meaning if you run on a cluster, the data
will be combined from many clusters and presents final result to you.

In SQL, ideally you can join whatever you want by making sure that the records on 2
tables match a condition. An example:

    SELECT post.*
      FROM post
      JOIN comment ON comment.post_id=post.id

    # OR

    SELECT post.*
      FROM post
      JOIN comment ON comment.author_id=post.author_id

You don't even need to care about the index. The database is usually smart
enough to figure out what index to use, or will scan the full table for you.

Join is a bit different in RethinkDB. Similar to how we have primary index and
second index, we usually need index to join in Rethink DB. Generally, we use
below techniques in a *JOIN* command:

* primary keys
* secondary indexes
* sub queries

Let's go over them one by one.

### Join with primary index

Starting with one-to-many relationship. Let's find all compound and its synonyms.
First, let see `eqJoin` syntax, a command for joining data is used to join data:

    sequence.eqJoin(leftField, rightTable[, {index:'id'}]) → sequence
    sequence.eqJoin(function, rightTable[, {index:'id'}]) → sequence

It tries to find the document on table **righTable** whose index value matches leftField value or the return value of function.
It's just similar to a normal `JOIN` in MySQL.

    SELECT
    FROM sequence
    JOIN rightTable
    ON sequence.leftField = rightTable.id

In plain English, `eqJoin` try to find pair of document on left table(sequence)
and rightTable whereas value of index of right table (default is the primary
index) matches value of leftField on left Table or the return value of execution
of function we passed into `eqJoin`

So, to find all compounds and its synonyms, we can do:

    r.db("foodb")
      .table("compound_synonyms")
      .eqJoin("compound_id", r.db("foodb").table("compounds"))

And we get this:

      "left": {
            "compound_id": 82 ,
            "created_at": Fri Apr 09 2010 17:40:05 GMT-07:00 ,
            "id": 832 ,
            "source":  "db_source" ,
            "synonym":  "3,4,2',4'-Tetrahydroxychalcone" ,
            "updated_at": Fri Apr 09 2010 17:40:05 GMT-07:00
          } ,
          "right": {
            "annotation_quality":  "low" ,
            "assigned_to_id": null ,
            "bigg_id": null ,
            "boiling_point": null ,
            "boiling_point_reference": null ,
            "cas_number": null ,
            "charge": null ,
            "charge_reference": null ,
            "chebi_id": null ,
            "comments": null ,
            "compound_source":  "PHENOLEXPLORER" ,
            "created_at": Thu Apr 08 2010 22:04:26 GMT-07:00 ,
            "creator_id": null ,
            "density": null ,
            "density_reference": null ,
            "wikipedia_id": null,
            //...lot of other fields
            ...
          }
          }

We get back an array, with element on both table match our condition. We can
see that the item on the left has its `compound_id` matchs `id` field of the
one on the right. However, the above result with left, right is not very useful.
It will be more useful if we can merge both side into a single document. To do
that, we use `zip`

    r.db("foodb")
      .table("compound_synonyms")
      .eqJoin("compound_id", r.db("foodb").table("compounds"))
      .zip()
    //=>
    {
      "annotation_quality":  "low" ,
      "assigned_to_id": null ,
      "bigg_id": null ,
      "boiling_point":  "Bp14 72°" ,
      "boiling_point_reference":  "DFC" ,
      "cas_number":  "15707-34-3" ,
      "charge": null ,
      "charge_reference": null ,
      "chebi_id": null ,
      "comments": null ,
      "compound_id": 923 ,
      //...lot of other fields
    },
    //other document here as well

What `zip` does is that it merges right document into left document and returns that document, instead of a document
with two **left** and **right** field.

`zip` is not really flexible because it simply merges all the field. We can use some **transform** function
to transform the document into a more read-able document since we only care about `name` and its `synonym`:

    r.db("foodb")
      .table("compound_synonyms")
      .eqJoin(
        "compound_id", 
        r.db("foodb").table("compounds")
      )
      .map(function (doc) {
        return {synonym: doc("left")("synonym"), name: doc("right")("name")}
      })
    //=>
    {
      "name":  "Butein" ,
      "synonym":  "Acrylophenone, 2',4'-dihydroxy-3-(3,4-dihydroxyphenyl)-"
    },
    {
      "name":  "3,4-Dimethoxybenzoic acid" ,
      "synonym":  "Benzoic acid, 3,4-dimethoxy-"
    }

Much cleaner now! The important thing is that the join data is just another stream or array
and we can do transformation on it.

As you may see, we didn't specify an index on above query. When we don't
specify index, RethinkDB use primary index of table. In this case, the primary key
is value of **id** field of table **compounds**. 

### Join with secondary index

Now loking at the previous query, it seems a bit awkard 
because table `compound_synonyms` comes first. We can make it more natural,
just follow above syntax: for each document on `compounds`, fetch all document on
`compound_synonyms` where document's `compound_id` field match value *id* of document
on `compounds` table. To do that, we have to have an index on 
`compound_synonyms` table for `compound_id` field. Let's create an index for it:

        r.db("foodb").table("compounds")
          .indexCreate("compound_id")

Note that we can always query index status by using `indexStatus`

        r.db("foodb").table("compound_synonyms").indexStatus()

Until we get status ready(this table is really big btw):

        [
        {
        "function": <binary, 185 bytes, "24 72 65 71 6c 5f..."> ,
        "geo": false ,
        "index":  "compound_id" ,
        "multi": false ,
        "outdated": false ,
        "ready": true
        }
        ]

Let's try it out:

    r.db("foodb")
      .table("compounds")
      .eqJoin("id", r.db("foodb").table("compound_synonyms"), {index: 'compound_id'})
      .map(function (doc) {
        return {synonym: doc("right")("synonym"), name: doc("left")("name")}
      })
    //=>
    {
    "name":  "Butein" ,
    "synonym":  "3-(3,4-Dihydroxy-phenyl)-1-(2,4-dihydroxy-phenyl)-propenone"
    } {
    "name":  "Butein" ,
    "synonym":  "2',3,4,4'-Tetrahydroxychalcone"
    }

With proper index, a query looks cleaner and more natural.
The order of how we use `eqJoin` is important. Trying narrow
down data first if possible, to make the join does less work.

Also, instead of passing the **field** name to `eqJoin`, we can also pass a
function or using `row` command to get value of nested field. In this case, 
the return value of function, or value of field access with `row`  will be
used to match with value of index on the right table. These are useful
especially with structure data on field.

Do you remember we have *users* table with data structure looks like this:

    r.db('foodb').table('users')
    {
      "age": 40 ,
      "eatenfoods": [
      "True sole" ,
      "Jerusalem artichoke" ,
      "Ascidians" ,
      "Pineappple sage" ,
      "Lotus" ,
      "Coffee and coffee products"
      ] ,
      "favfoods": [
      "Edible shell" ,
      "Clupeinae (Herring, Sardine, Sprat)" ,
      "Deer" ,
      "Perciformes (Perch-like fishes)" ,
      "Bivalvia (Clam, Mussel, Oyster)"
      ] ,
      "gender":  "m" ,
      "id":  "1dd8059c-82ca-4345-9d75-eaa0f8edbf48" ,
      "name":  "Arthur Hegmann"
      ...
    }

Let's try to find more information about the most favourite foods.

First, let's create an index for *food name*

    r.db('foodb').table('foods').indexCreate('name')

With that index, we can join data:

    r.db('foodb').table('users')
      .eqJoin(r.row('favfoods').nth(0), r.db('foodb').table('foods'), {index: 'name'})
    //=>
    {
        "left": {
            "age": 40,
            "eatenfoods": [
                "True sole",
                "Jerusalem artichoke",
                "Ascidians",
                "Pineappple sage",
                "Lotus",
                "Coffee and coffee products"
            ],
            "favfoods": [
                "Edible shell",
                "Clupeinae (Herring, Sardine, Sprat)",
                "Deer",
                "Perciformes (Perch-like fishes)",
                "Bivalvia (Clam, Mussel, Oyster)"
            ],
            "gender": "m",
            "id": "1dd8059c-82ca-4345-9d75-eaa0f8edbf48",
            "name": "Arthur Hegmann"
        },
        "right": {
            "created_at": Wed Dec 21 2011 02: 40: 48 GMT - 08: 00,
            "creator_id": 2,
            "description": null,
            "food_group": "Baking goods",
            "food_subgroup": "Wrappers",
            "food_type": "Type 2",
            "id": 868,
            "itis_id": null,
            "legacy_id": null,
            "name": "Edible shell",
            "name_scientific": null,
            "picture_content_type": "image/jpeg",
            "picture_file_name": "868.jpg",
            "picture_file_size": 51634,
            "picture_updated_at": Fri Apr 20 2012 09: 39: 05 GMT - 07: 00,
            "updated_at": Fri Apr 20 2012 16: 39: 06 GMT - 07: 00,
            "updater_id": 2,
            "wikipedia_id": null
        }
    }
    //....

We can have the same result, using *function* syntax

    r.db('foodb').table('users')
      .eqJoin(function(user) { return user('favfoods').nth(0) }, 
              r.db('foodb').table('foods'), 
              {index: 'name'})

So basically passing field name is just a shortcut when using `r.row(field_name)`.
Using `row` or function gives us much more flexibility. Also remember that
`row` command cannot be used in any sub queries such as in this case:

Let's say we have a 

Since the beginning, the way *join* is constructed is to match the document
between 2 tables based on value and matching of index. How we can just simply
join data across two table based on two *field*? In real life, we may have even
more complex *join* condition. Example, in MySQL, we can join with, basically
any arbitrary condition like this:

    SELECT *
      FROM table1 as t1
    JOIN tabl2 as t2 ON t1.field1=t2.field1 AND t1.foo=t2.bar

Let's think of an example. I want to join data of table *compounds* and its 
*compounds_synonyms* where the source is from **biospider** and created after
2013. It is obviously we cannot use a single field here with `eqJoin`.

Luckily, we have another way of joining data, using sub queries with `concatMap`
and `getAll`. However, since they are not `eqJoin` command, we will learn about
sub query later in this chapter. For now, let's move on to other *join* command.

To join, we usually need index. But can we join data without using any index
via two arbitray sequence? Even if it's not very efficient but useful to have.
The answer is yes, we can do inner join and outer join.

## innerJoin

innerJoin returns an inter section of two sequences where as each row of first
sequence will be put together with each row of second sequence, then evaluates
a predicate function to find pair of rows which predicate function returns true.
The syntax of `innerJoin` is:

    sequence.innerJoin(otherSequence, predicate) → stream
    array.innerJoin(otherSequence, predicate) → array

Predicate function accepts two parameters of each row of first and second
sequence.

Let's say the first sequence has `M` rows, and second sequence has `N` rows,
the innerJoin will loop ***M x N*** times and pass the pair of rows into
predicate function. Let's say we have two sequences:

    [2,5,8,12,15,20,21,24,25]
    [2,3,4]

And we want to find all pair of data where the first element module and second
element equals zero.

We can write this:

    r.expr([2,5,8,12,15,20,21,24,25])
      .innerJoin(
        r.expr([2,3,4]),
        function (left, right) {
          return left.mod(right).eq(0)
        }
      )
    //=>
    [
    {
    "left": 2 ,
    "right": 2
    } ,
    {
    "left": 8 ,
    "right": 2
    } ,
    {
    "left": 8 ,
    "right": 4
    } ,
    {
    "left": 12 ,
    "right": 2
    } ,
    {
    "left": 12 ,
    "right": 3
    } ,
    {
    "left": 12 ,
    "right": 4
    } ,
    {
    "left": 15 ,
    "right": 3
    } ,
    {
    "left": 20 ,
    "right": 2
    } ,
    {
    "left": 20 ,
    "right": 4
    } ,
    {
    "left": 21 ,
    "right": 3
    } ,
    {
    "left": 24 ,
    "right": 2
    } ,
    {
    "left": 24 ,
    "right": 3
    } ,
    {
    "left": 24 ,
    "right": 4
    }
    ]

RethinkDB will loop 27 times(9x3) and evaluate function to find rows. Because
of the evaluation, and no index is involved, this function is slow.

Here is another real example with real data. Let's find all `foods` and its `compound_foods`.

    r.db("foodb")
      .table("foods")
      .innerJoin(
        r.db("foodb").table("compounds_foods"),
        function(food, compound_food) {
          return food("id").eq(compound_food("food_id"))
        }
      )
    //=>
    {
    "left": {
    "created_at": Wed Feb 09 2011 00:37:15 GMT-08:00 ,
    "creator_id": null ,
    "description": null ,
    "food_group":  "Vegetables" ,
    "food_subgroup":  "Cabbages" ,
    "food_type":  "Type 1" ,
    "id": 2 ,
    "itis_id": null ,
    "legacy_id": 2 ,
    "name":  "Savoy cabbage" ,
    "name_scientific":  "Brassica oleracea var. sabauda" ,
    "picture_content_type":  "image/jpeg" ,
    "picture_file_name":  "2.jpg" ,
    "picture_file_size": 155178 ,
    "picture_updated_at": Fri Apr 20 2012 09:39:54 GMT-07:00 ,
    "updated_at": Fri Apr 20 2012 16:39:55 GMT-07:00 ,
    "updater_id": null ,
    "wikipedia_id": null
    } ,
    "right": {
    "citation":  "DTU" ,
    "citation_type":  "DATABASE" ,
    "compound_id": 13831 ,
    "created_at": Tue Dec 13 2011 18:54:33 GMT-08:00 ,
    "creator_id": null ,
    "food_id": 2 ,
    "id": 15619 ,
    "orig_citation": null ,
    "orig_compound_id":  "0014" ,
    "orig_compound_name":  "Vitamin A, total" ,
    "orig_content":  "0.5E2" ,
    "orig_food_common_name":  "Cabbage, savoy, raw" ,
    "orig_food_id":  "0674" ,
    "orig_food_part": null ,
    "orig_food_scientific_name": null ,
    "orig_max": null ,
    "orig_method": null ,
    "orig_min": null ,
    "orig_unit":  "RE" ,
    "orig_unit_expression": null ,
    "updated_at": Tue Dec 13 2011 18:54:33 GMT-08:00 ,
    "updater_id": null
    }
    } {
    "left": {
    "created_at": Wed Feb 09 2011 00:37:15 GMT-08:00 ,
    "creator_id": null ,
    "description": null ,
    "food_group":  "Vegetables" ,
    "food_subgroup":  "Cabbages" ,
    "food_type":  "Type 1" ,
    "id": 2 ,
    "itis_id": null ,
    "legacy_id": 2 ,
    "name":  "Savoy cabbage" ,
    "name_scientific":  "Brassica oleracea var. sabauda" ,
    "picture_content_type":  "image/jpeg" ,
    "picture_file_name":  "2.jpg" ,
    "picture_file_size": 155178 ,
    "picture_updated_at": Fri Apr 20 2012 09:39:54 GMT-07:00 ,
    "updated_at": Fri Apr 20 2012 16:39:55 GMT-07:00 ,
    "updater_id": null ,
    "wikipedia_id": null
    } ,
    "right": {
    "citation":  "DTU" ,
    "citation_type":  "DATABASE" ,
    "compound_id": 1014 ,
    "created_at": Tue Dec 13 2011 18:54:33 GMT-08:00 ,
    "creator_id": null ,
    "food_id": 2 ,
    "id": 15630 ,
    "orig_citation": null ,
    "orig_compound_id":  "0038" ,
    "orig_compound_name":  "Niacin, total" ,
    "orig_content":  "0.522E0" ,
    "orig_food_common_name":  "Cabbage, savoy, raw" ,
    "orig_food_id":  "0674" ,
    "orig_food_part": null ,
    "orig_food_scientific_name": null ,
    "orig_max": null ,
    "orig_method": null ,
    "orig_min": null ,
    "orig_unit":  "NE" ,
    "orig_unit_expression": null ,
    "updated_at": Tue Dec 13 2011 18:54:33 GMT-08:00 ,
    "updater_id": null
    }
    }

It will run forever, because we have 888 documents in `food` table, and `10959` document
in `compound_foods` table. It has to run the predicate function
888 * 10959 = 9,731,592 time. On my laptop, it runs in:

C> Executed in 2min 25.86s. 40 rows returned, 40 displayed, more available

Basically `innerJoin` is equivalent of table scan in MySQL. We should avoid
using it on any significant amount data.

## outerJoin

`innerJoin` is an intersection of two sequences where a pair of documents sastify
a condition. How about something similar to an `left join` in SQL? Let's meet `outerJoin`

`outerJoin` will return all documents of left sequences. With each document,
it will try to match with every documents of right hand. If the pair sastify
a predicate function, the pair is returned. If not, the only document of left
sequence is returned. At very least, the finaly sequence will include all
document of left sequence. Using same data set, but for `outerJoin`:

    r.expr([2,5,8,12,15,20,21,24,25])
      .outerJoin(
        r.expr([2,3,4]),
        function (left, right) {
          return left.mod(right).eq(0)
        }
      )
    //=>
    [
    {
    "left": 2 ,
    "right": 2
    } ,
    {
    "left": 5
    } ,
    {
    "left": 8 ,
    "right": 2
    } ,
    {
    "left": 8 ,
    "right": 4
    } ,
    {
    "left": 12 ,
    "right": 2
    } ,
    {
    "left": 12 ,
    "right": 3
    } ,
    {
    "left": 12 ,
    "right": 4
    } ,
    {
    "left": 15 ,
    "right": 3
    } ,
    {
    "left": 20 ,
    "right": 2
    } ,
    {
    "left": 20 ,
    "right": 4
    } ,
    {
    "left": 21 ,
    "right": 3
    } ,
    {
    "left": 24 ,
    "right": 2
    } ,
    {
    "left": 24 ,
    "right": 3
    } ,
    {
    "left": 24 ,
    "right": 4
    } ,
    {
    "left": 25
    }
    ]

**5** and **25** were not divided by any of the number on right hand. Therfore,
the return document contains only left hand document.

## Name conflict

In SQL worlds, we can alias column to avoid conflict when joining. What
RethinkDB gives us, when we used `zip` command to merge the document? We
will loose the column on left sequence. We have several ways to address this.

Firstly, if we want to use `zip`:

    *  Removing conflict fields: By simply remove the field we don't want,
       we can get what we want.

    *  What if we want to keep both fields? We can rename it, using `map`.

Secondly, we don't have to use `zip`, and we can merge document itself with
`map`, and only keep what we want.

However, we are still not able to address this issues. Those are just work-around. Luckily,
RethinkDB team are aware of that and is working on it now[^collapse].

[^collapse]: https://github.com/rethinkdb/rethinkdb/issues/1855

## Using sub queries

As I promised before, in many complex case, `eqJoin` won't work for us. And we
can use `concatMap` and `getAll`. Now is the time to learn them. We will slowly
go over some kind of relation again.

### One to many relation

Almost above JOIN commands is operator on two sequence. What if we have exactly
a single document which we get by using `get` and we want to join some data.
If we think a bit, we can see that in RethinkDB, we can query whatever extra
data inside an anonoymous function. What if we query extra data inside those
function then merge it with parent document. It will has same effect as a JOIN.
Let's do it. Let's say we want to know flavors of Kiwi, a fruit that we never
eat. We had a table **compounds_flavors** which contains association of a
*compound* and a *flavor*. We have table *compounds_foods* which contains
association of a *compound* and a *food*. So basically, we can do this:

  * Given a food, we know its ID
  * Find all of its *compound* using **compound_foods** tables.
  * With each of compound, we know its flavor, by query *compound_flavors*
    to find association with *flavors* table. In other words, to find the
    *flavor_id* for that compounds.

First of all, we needs some index:

    // We need this index to look up by food_id on `compounds_foods`
    r.db('foodb').table('compounds_foods').indexCreate('food_id')

    // We need this index to find on `compounds_falvors` by compound_id
    r.db("foodb").table("compounds_flavors").indexCreate('compound_id')

With that index, let's build our query step by step. First, we select Kiwi,
its ID is *4*. Then calling *merge* command. 

    r.db("foodb")
      .table("foods")
      .get(4)
      .merge(function (food) {

        return {
          flavors: //flavor array here
        }
      })

Let's see what will we fill in **flavors** array. We will try to grab all of
its compound. That means all of *documents* of *compounds_foods* table where
its *food_id* is equal with main ID of kiwi.

    r.db("foodb")
      .table("foods")
      .get(4)
      .merge(function (food) {
        return {
          flavors:
              r.db("foodb").table("compounds_foods")
                  .getAll(food("id"),{index: "food_id"})
                  .concatMap(function(compound_food) {
                    //Return something flavor of compound here
                  })
                  .coerceTo("array")
        }
      })

Notice that we used `concatMap` so that it flattens array for us. We also used
 `coerceTo` to convert selection result to an array for `merge` command.
With each of document of *compounds_foods* we can baiscally get all of its 
flavor as following:

    r.db("foodb").table("compounds_flavors")
                        .getAll(compound_food("compound_id"), {index: "compound_id"})
                        .concatMap(function(compounds_flavor) {
                        return
                          r.db("foodb").table("flavors").getAll(compounds_flavor("flavor_id"))
                          .map(function (flavor) {
                            return flavor("name")
                          })
                        .coerceTo("array")
                        })
                            .coerceTo("array")

Putting together, we have this final giant, scary query:

    r.db("foodb")
      .table("foods")
      .get(4)
      .merge(function (food) {

        return {
          flavors: 
              r.db("foodb").table("compounds_foods")
                  .getAll(food("id"),{index: "food_id"})
                  .concatMap(function(compound_food) {
                      return 
                      r.db("foodb").table("compounds_flavors")
                        .getAll(compound_food("compound_id"), {index: "compound_id"})
                        .concatMap(function(compounds_flavor) {
                          return
                            r.db("foodb").table("flavors").getAll(compounds_flavor("flavor_id"))
                            .map(function (flavor) {
                              return flavor("name")
                            })
                            .coerceTo("array")
                        })
                        .coerceTo("array")


                  })
                  .distinct()
                  .coerceTo("array")
        }

      })

Before the final `coerceTo`, we also call `distinct` to eliminate duplicate.
And we got this result:

    {
        "created_at": Wed Feb 09 2011 00: 37: 15 GMT - 08: 00,
        "creator_id": null,
        "description": null,
        "flavors": [
            "alcoholic",
            "baked",
            "bay oil",
            "bitter",
            "bland",
            "bread",
            "cheese",
            "cheesy",
            "citrus",
            "coconut",
            "ethereal",
            "faint",
            "fat",
            "fatty",
            "medical",
            "metal",
            "mild",
            "odorless",
            "rancid",
            "slightly waxy",
            "soapy",
            "sour",
            "strong",
            "sweat",
            "sweet",
            "unpleasant",
            "waxy",
            "yeast"
        ],
        "food_group": "Fruits",
        "food_subgroup": "Tropical fruits",
        "food_type": "Type 1",
        "id": 4,
        "itis_id": "506775",
        "legacy_id": 4,
        "name": "Kiwi",
        "name_scientific": "Actinidia chinensis",
        "picture_content_type": "image/jpeg",
        "picture_file_name": "4.jpg",
        "picture_file_size": 110661,
        "picture_updated_at": Fri Apr 20 2012 09: 32: 21 GMT - 07: 00,
        "updated_at": Fri Apr 20 2012 16: 32: 22 GMT - 07: 00,
        "updater_id": null,
        "wikipedia_id": null
    }

While as the query looks giant and complex. The way to write is to drill down
each table at a time, using a map/concatMap to transform data.

### Many to many relation

Using of `outerJoin` and `innerJoin` are not efficient because they are not
using index at all. They are useful, like filter, powerful too but just not
very fast. As in *Chapter 5*, we used `concatMap` with `getAll` to query
data across tables, that is just an idea of *JOIN*. We should always avoid
`outerJoin` and `innerJoin` if possible and adopt `getAll` with `concatMap`.

In **inner join** section, it takes more than 2 minutes to run our query.
Let's try it again, find all *foods* and its *compounds_founds*, this time we
leverage an index with `getAll` and join data with `concatMap`

    r.db('foodb').table('foods')
      .map(function (food) {
        return food.merge({
          "compound_foods":
            r.db('foodb').table('compounds_foods')
              .getAll(food("id"), {index: 'food_id'})
              .coerceTo('array')
        })
      })

And how fast it runs:

C> Executed in 1.52s. 40 rows returned, 40 displayed, more available

Much better than using `innerJoin`.Compare to >2mins before, this is 
a major improvement. To really see how fast/slow a query
without index, you may want to put data on a spin disk(an external hard drive
for example), because SSD is usually fast and you may not notice. All of
my above example is using a SSD on  Macbook Pro (Retina, 13-inch, Mid 2014),
with process Interl Core i5 2.8ghz and 16GB RAM.

The key point is to ensure we get data using index. For each of document, we
join data by run other query in a `map`/`concatMap` function to merge/transform
extra data. The merge document is returned instead of original document

The main different between using sub query is that we have nested document
instead of **left** **right** field like in JOIN. However, via using some map or
transform command we can turn them into whatever we can imagine.

# Why map/concatMap is important

In SQL, we can basically join whatever. In RethinkDB, join is infact just a syntaxtic
sugar on top of `getAll` and `concatMap`. As you learn in *Chapter 5*, `map`/`concatMap`
allow you to transform data with its relation data in an associated table, by
querying extra data inside map function.

I once say that they are important and now I repeated again because they are
everything. `getAll` is just like *SELECT* in MySQL in term of how much
you have to use. And `getAll` is not very useful without a `map`.

# Wrap up

At the end of this chapter, we should know how to join based on these concepts:

  * Primary key: the ID field of document
  * Secondary index: join using secondary index
  * Sub queries: using merge, map/concatMap to join data
